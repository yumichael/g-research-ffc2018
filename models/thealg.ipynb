{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/pandas/core/common.py:701: RuntimeWarning: divide by zero encountered in log\n",
      "  return func(obj, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from common import *\n",
    "from numba import jit\n",
    "from heapq import *\n",
    "nan32 = (np.array(0.0, dtype=np.float32) + np.nan).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### high level redesign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TheAlg():\n",
    "    def __init__(a, X, Y, W, s, mvalid, algorithm, alltrain=False):\n",
    "        a.alltrain = alltrain or not s.ho.sum()\n",
    "        a._alg_evaluate = a._get_algorithm(algorithm, alltrain=alltrain)\n",
    "        a._alg_finalize = a._get_algorithm(algorithm, finalize=True, alltrain=alltrain)\n",
    "        a.s = s\n",
    "        a.mvalid = mvalid.values\n",
    "        a.k = X.columns.get_level_values(0).nunique() # features\n",
    "        a.m = X.columns.get_level_values(1).nunique() # stocks/groups\n",
    "        a.columns = X.columns\n",
    "        a._def_matrices(X, Y, W, s) # Y not demeaned yet to get the no mean baseline score\n",
    "        a._setup()\n",
    "        a._args = ()\n",
    "        \n",
    "    def _setup(a):\n",
    "        a.scores = {}\n",
    "        a.scores[None] = a._calc_baseline()\n",
    "        a.scores[None] = (a.scores[None][0], 1) if a.scores[None][1] == 0 else a.scores[None]\n",
    "        a.meandata = (a.Y.tc * a.W.tc).sum(axis=0) / _replace_0_1(a.W.tc.sum(axis=0))\n",
    "        a.meandatafn = (a.Y.tc * a.W.tc).sum(axis=0) + (a.Y.ho * a.W.ho).sum(axis=0)\n",
    "        a.meandatafn /= _replace_0_1(a.W.tc.sum(axis=0) + a.W.ho.sum(axis=0))\n",
    "        for sp in a.Y: # loop to demean Y\n",
    "            a.Y[sp] -= a.meandata\n",
    "        a.vardata = (a.Y.tc ** 2 * a.W.tc).sum(axis=0)\n",
    "        a.scores[()] = a._calc_baseline()\n",
    "        a.fbnums = {None: None, (): None}\n",
    "        a.over = set()\n",
    "        \n",
    "    def _def_matrices(a, X, Y, W, s):\n",
    "        a.X, a.Y, a.W = O(), O(), O()\n",
    "        for aZ, Z in zip([a.X, a.Y, a.W], [X, Y, W]):\n",
    "            aZ.tc = Z[s.tc].values\n",
    "            aZ.d0 = np.stack([Z[tr].values for tr, cv in s.trcv])\n",
    "            aZ.d1 = np.stack([Z[cv].values for tr, cv in s.trcv])\n",
    "            aZ.ho = Z[s.ho].values\n",
    "            aZ.aw = Z.values\n",
    "        \n",
    "    def _calc_baseline(a):\n",
    "        return (sum(_lr_rss(y, np.zeros_like(y), w) for y, w in zip(a.Y.tc, a.W.tc)),\n",
    "                sum(_lr_rss(y, np.zeros_like(y), w) for y, w in zip(a.Y.ho, a.W.ho)))\n",
    "    \n",
    "    def _get_algorithm(a, name, finalize=False, alltrain=False):\n",
    "        if finalize:\n",
    "            alg = 'finalize'\n",
    "        elif alltrain:\n",
    "            alg = 'alltrain'\n",
    "        else:\n",
    "            alg = 'evaluate'\n",
    "        return globals()['_alg_' + alg + '_' + name]\n",
    "            \n",
    "    def alg1(a, start=(), branch=1, branch_at_depth=None, max_depth=4, print=print, dot=1, numdot=10):\n",
    "        a._alg1 = O(branch=branch, branch_at_depth=branch_at_depth, max_depth=max_depth,\n",
    "                    print=print, dot=dot, numdot=numdot)\n",
    "        a._alg1_recur(start, depth=0)\n",
    "        \n",
    "    def _alg1_recur(a, feats, depth):\n",
    "        feats, o, print = feats, a._alg1, a._alg1.print\n",
    "        print((a.scores[feats][0] / a.scores[None][0], a.scores[feats][1] / a.scores[None][1]), a.fbnums[feats], len(feats))\n",
    "        print('[' + ', '.join(str(a.columns[a.m * f][0]) for f in feats) + '] ' + str(feats))\n",
    "        print(flush=True)\n",
    "        if depth >= o.max_depth:\n",
    "            return\n",
    "        print('<{}>'.format(a.k - len(feats)), end=' ', flush=True)\n",
    "        heap = []\n",
    "        for i, f in enumerate(set(range(a.k)) - set(feats)):\n",
    "            print('.' if i // o.dot % o.numdot else i, end='', flush=True) if i % o.dot == 0 else None\n",
    "            newfeats = tuple(sorted(feats + (f,)))\n",
    "            if newfeats not in a.scores:\n",
    "                newscore, newfbnum = a._alg_evaluate(a.X.d0, a.Y.d0, a.W.d0,\n",
    "                                                     a.X.d1, a.Y.d1, a.W.d1,\n",
    "                                                     a.X.tc, a.Y.tc, a.W.tc,\n",
    "                                                     a.X.ho, a.Y.ho, a.W.ho,\n",
    "                                                     a.m, a.mvalid, a.vardata,\n",
    "                                                     a.k, np.array(newfeats, dtype=np.int64), a.s.n_folds, *a._args)\n",
    "                a.scores[newfeats] = newscore\n",
    "                a.fbnums[newfeats] = newfbnum\n",
    "            if a.scores[newfeats][0] < a.scores[feats][0]:\n",
    "                heap.append((a.scores[newfeats][0], newfeats))\n",
    "            else:\n",
    "                a.over.add(newfeats)\n",
    "        print('\\n', flush=True)\n",
    "        heap.sort()\n",
    "        for score0, f in heap[:o.branch_at_depth(depth) if o.branch_at_depth else o.branch]:\n",
    "            a._alg1_recur(f, depth + 1)\n",
    "        \n",
    "    def alg2(a, start=None, top=None, score=None, tight=False, print=print, dot=1, numdot=10):\n",
    "        o = O(dot=dot, numdot=numdot)\n",
    "        assert (top is not None) + (score is not None) + (start is not None) == 1\n",
    "        start = a.scores if start is None else start\n",
    "        heap = sorted((a.scores[f][0], f) for f in start if f not in a.over)\n",
    "        score = float('inf') if score is None else score\n",
    "        searchlim = heap[top][0] if top is not None else score\n",
    "        while heap and heap[0][0] < searchlim:\n",
    "            if tight:\n",
    "                searchlim = heap[0][0]\n",
    "            feats = heappop(heap)[1]\n",
    "            print((a.scores[feats][0] / a.scores[None][0], a.scores[feats][1] / a.scores[None][1]),\n",
    "                  a.fbnums[feats], len(feats))\n",
    "            print('[' + ', '.join(str(a.columns[a.m * f][0]) for f in feats) + '] ' + str(feats))\n",
    "            print(flush=True)\n",
    "            print('<{}>'.format(a.k - len(feats)), end=' ', flush=True)\n",
    "            for i, f in enumerate(set(range(a.k)) - set(feats)):\n",
    "                print('.' if i // o.dot % o.numdot else i, end='', flush=True) if i % o.dot == 0 else None\n",
    "                newfeats = feats + (f,)\n",
    "                if newfeats not in a.scores:\n",
    "                    newscore, newfbnum = a._alg_evaluate(a.X.d0, a.Y.d0, a.W.d0,\n",
    "                                                         a.X.d1, a.Y.d1, a.W.d1,\n",
    "                                                         a.X.tc, a.Y.tc, a.W.tc,\n",
    "                                                         a.X.ho, a.Y.ho, a.W.ho,\n",
    "                                                         a.m, a.mvalid, a.vardata,\n",
    "                                                         a.k, np.array(newfeats, dtype=np.int64), a.s.n_folds, *a._args)\n",
    "                    a.scores[newfeats] = newscore\n",
    "                    a.fbnums[newfeats] = newfbnum\n",
    "                    if a.scores[newfeats][0] < a.scores[feats][0]:\n",
    "                        heappush(heap, (a.scores[newfeats][0], newfeats))\n",
    "                    else:\n",
    "                        a.over.add(newfeats)\n",
    "            print('\\n', flush=True)\n",
    "            \n",
    "    def final(a, feats_list, args_list, weight_list=None, dry=False, dot=1, numdot=10, average=True):\n",
    "        print('<{}>'.format(len(feats_list)), end=' ', flush=True)\n",
    "        weight_list = [1 for i in range(len(args_list))] if weight_list is None else weight_list\n",
    "        Y_ = []\n",
    "        for i, (feats, args, weight) in enumerate(zip(feats_list, args_list, weight_list)):\n",
    "            print('.' if i // dot % numdot else i, end='', flush=True) if i % dot == 0 else None\n",
    "            if dry:\n",
    "                md, y_ = a._alg_finalize(a.X.tc, a.Y.tc, a.W.tc, a.X.aw,\n",
    "                                         a.m, a.mvalid, a.k, np.array(feats, dtype=np.int64), *args)\n",
    "            elif a.alltrain:\n",
    "                md, y_ = a._alg_finalize(a.X.tc, a.Y.tc, a.W.tc, a.X.aw,\n",
    "                                         a.m, a.mvalid, a.k, np.array(feats, dtype=np.int64), *args)\n",
    "            else:\n",
    "                md, y_ = a._alg_finalize(np.concatenate([a.X.tc, a.X.ho]),\n",
    "                                         np.concatenate([a.Y.tc, a.Y.ho]),\n",
    "                                         np.concatenate([a.W.tc, a.W.ho]), a.X.aw,\n",
    "                                         a.m, a.mvalid, a.k, np.array(feats, dtype=np.int64), *args)\n",
    "            Y_.append(weight * y_ if average else y_)\n",
    "        print(flush=True)\n",
    "        if average:\n",
    "            return np.stack(Y_).sum(axis=0) / sum(weight_list) + (a.meandata if dry else a.meandatafn)\n",
    "        else:\n",
    "            return [y_ + (a.meandata if dry else a.meandatafn) for y_ in Y_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _replace_0_1(a):\n",
    "    a[a == 0] = 1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True) #doesn't work / overfits\n",
    "def _alg_evaluate_super(X0, Y0, W0, X1, Y1, W1, Xt, Yt, Wt, Xh, Yh, Wh, m, mvalid, mbase, k, subk, f):\n",
    "    tc = np.empty(m, dtype=Yt.dtype) + nan32\n",
    "    ho = np.empty(m, dtype=Yh.dtype) + nan32\n",
    "    tck = np.empty((m, subk.shape[0] + 1), dtype=Yt.dtype) + nan32\n",
    "    hok = np.empty((m, subk.shape[0] + 1), dtype=Yh.dtype) + nan32\n",
    "    #model = np.empty((m, subk.shape[0]), dtype=Xt.dtype) + nan32\n",
    "    repeatf = X0.shape[0]\n",
    "    fbn = 0\n",
    "    fulln = 0\n",
    "    for g in range(m):\n",
    "        tck[g, 0] = mbase[g] * (repeatf // f)\n",
    "        hok[g, 0] = _lr_rss(Yh[:, g], 0, Wh[:, g])\n",
    "        for j in range(1, subk.shape[0] + 1):\n",
    "            head = subk[:j]\n",
    "            X0g, Y0g, W0g, X1g, Y1g, W1g, xt, yt, wt, xh, yh, wh = (\n",
    "                X0[:, :, g::m][:, :, head], Y0[:, :, g], W0[:, :, g],\n",
    "                X1[:, :, g::m][:, :, head], Y1[:, :, g], W1[:, :, g],\n",
    "                Xt[:, g::m][:, head], Yt[:, g], Wt[:, g],\n",
    "                Xh[:, g::m][:, head], Yh[:, g], Wh[:, g])\n",
    "            tcg = np.empty(repeatf, dtype=Y0g.dtype) + nan32\n",
    "            for i in range(repeatf):\n",
    "                x0, y0, w0, x1, y1, w1 = X0g[i], Y0g[i], W0g[i], X1g[i], Y1g[i], W1g[i]\n",
    "                beta = _lr_fit(x0, y0, w0)\n",
    "                y1_ = _lr_predict(x1, beta)\n",
    "                tcg[i] = _lr_rss(y1, y1_, w1)\n",
    "            tcg.sort()\n",
    "            tck[g, j] = tcg.sum()\n",
    "            beta = _lr_fit(xt, yt, wt)\n",
    "            yh_ = _lr_predict(xh, beta)\n",
    "            hok[g, j] = _lr_rss(yh, yh_, wh)\n",
    "    for j in range(subk.shape[0] + 1):\n",
    "        pass\n",
    "    tc.sort()\n",
    "    ho.sort()\n",
    "    return (tc.sum() / (repeatf // f), ho.sum()), (fbn, m - fulln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def _exp_weigh(x, a):\n",
    "    return x * (1 - np.exp(-a))\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _alg_evaluate_expfb(X0, Y0, W0, X1, Y1, W1, Xt, Yt, Wt, Xh, Yh, Wh, m, mvalid, mbase, k, subk, f, _val, _exp):\n",
    "    Mval, Mexp = len(_val), len(_exp)\n",
    "    tc = np.zeros((m, Mval, Mexp), dtype=Yt.dtype) # zeros because we need to add to this for each fold\n",
    "    ho = np.empty((m, Mval, Mexp), dtype=Yh.dtype) + nan32 # nans because we only set each value once for the HO set\n",
    "    #model = np.empty((m, subk.shape[0]), dtype=Xt.dtype) + nan32\n",
    "    repeatf = X0.shape[0]\n",
    "    for g in range(m): # loop for each stock\n",
    "        X0g, Y0g, W0g, X1g, Y1g, W1g, xt, yt, wt, xh, yh, wh = (\n",
    "            X0[:, :, g::m][:, :, subk], Y0[:, :, g], W0[:, :, g],\n",
    "            X1[:, :, g::m][:, :, subk], Y1[:, :, g], W1[:, :, g],\n",
    "            Xt[:, g::m][:, subk], Yt[:, g], Wt[:, g],\n",
    "            Xh[:, g::m][:, subk], Yh[:, g], Wh[:, g])\n",
    "        ############## TRCV dataset\n",
    "        for p in range(repeatf): # loop for each cv-fold\n",
    "            x0, y0, w0, x1, y1, w1 = X0g[p], Y0g[p], W0g[p], X1g[p], Y1g[p], W1g[p]\n",
    "            beta = _lr_fit(x0, y0, w0)\n",
    "            y1_ = _lr_predict(x1, beta)\n",
    "            # search over the exp fallback\n",
    "            thei = Mval\n",
    "            for i in range(Mval): # i + 1 = min num of obs in stock - ddof to use lin model\n",
    "                if _val[i] >= mvalid[g] - subk.shape[0]:\n",
    "                    thei = i\n",
    "                    break\n",
    "                tc[g, i, 0] += _lr_rss(y1, y1_, w1) # when j == 0 just use the linear model\n",
    "                for j in range(1, Mexp): # j denotes exponential weighting argument\n",
    "                    y1_fb = _exp_weigh(y1_, (mvalid[g] - subk.shape[0] - _val[i]) / _exp[j])\n",
    "                    tc[g, i, j] += _lr_rss(y1, y1_fb, w1)\n",
    "        # outside the cv-fold loop\n",
    "        tc[g] /= repeatf // f # divide by number of times trcv set was repeated over\n",
    "        tc[g, thei:] = mbase[g] # fill in the mean model prediction errors for when mvalid[g] < i\n",
    "        ############# HO dataset\n",
    "        beta = _lr_fit(xt, yt, wt)\n",
    "        #model[g] = beta\n",
    "        yh_ = _lr_predict(xh, beta)\n",
    "        # search over the exp fallback\n",
    "        thei = Mval\n",
    "        for i in range(Mval): # i + 1 = min num of obs in stock - ddof to use lin model\n",
    "            if _val[i] >= mvalid[g] - subk.shape[0]:\n",
    "                thei = i\n",
    "                break\n",
    "            ho[g, i, 0] = _lr_rss(yh, yh_, wh) # when j == 0 just use the linear model\n",
    "            for j in range(1, Mexp): # j denotes exponential weighting argument\n",
    "                yh_fb = _exp_weigh(yh_, (mvalid[g] - subk.shape[0] - _val[i]) / _exp[j])\n",
    "                ho[g, i, j] = _lr_rss(yh, yh_fb, wh)\n",
    "        ho[g, thei:] = _lr_rss(yh, 0, wh) # fill in the mean model prediction errors for when mvalid[g] < i\n",
    "        #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%\n",
    "    tcfb, hofb = tc.sum(axis=0), ho.sum(axis=0)\n",
    "    hoij, hobest = hofb.argmin(), hofb.min()\n",
    "    tcij, tcbest = tcfb.argmin(), tcfb.min()\n",
    "    return (tcbest, hobest), ((_val[tcij // Mexp], _exp[tcij % Mexp]), (_val[hoij // Mexp], _exp[hoij % Mexp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def _alg_evaluate_fb(X0, Y0, W0, X1, Y1, W1, Xt, Yt, Wt, Xh, Yh, Wh, m, mvalid, mbase, k, subk, f):\n",
    "    tc = np.empty(m, dtype=Yt.dtype) + nan32\n",
    "    ho = np.empty(m, dtype=Yh.dtype) + nan32\n",
    "    #model = np.empty((m, subk.shape[0]), dtype=Xt.dtype) + nan32\n",
    "    repeatf = X0.shape[0]\n",
    "    for g in range(m):\n",
    "        X0g, Y0g, W0g, X1g, Y1g, W1g, xt, yt, wt, xh, yh, wh = (\n",
    "            X0[:, :, g::m][:, :, subk], Y0[:, :, g], W0[:, :, g],\n",
    "            X1[:, :, g::m][:, :, subk], Y1[:, :, g], W1[:, :, g],\n",
    "            Xt[:, g::m][:, subk], Yt[:, g], Wt[:, g],\n",
    "            Xh[:, g::m][:, subk], Yh[:, g], Wh[:, g])\n",
    "        tcg = np.empty(repeatf, dtype=Y0g.dtype) + nan32\n",
    "        for i in range(repeatf):\n",
    "            x0, y0, w0, x1, y1, w1 = X0g[i], Y0g[i], W0g[i], X1g[i], Y1g[i], W1g[i]\n",
    "            beta = _lr_fit(x0, y0, w0)\n",
    "            y1_ = _lr_predict(x1, beta)\n",
    "            tcg[i] = _lr_rss(y1, y1_, w1)\n",
    "        tcg.sort()\n",
    "        tc[g] = tcg.sum()\n",
    "        beta = _lr_fit(xt, yt, wt)\n",
    "        #model[g] = beta\n",
    "        yh_ = _lr_predict(xh, beta)\n",
    "        ho[g] = _lr_rss(yh, yh_, wh)\n",
    "    MAX_VALID = 128\n",
    "    tcfb = np.empty(MAX_VALID, dtype=tc.dtype) + nan32\n",
    "    hofb = np.empty(MAX_VALID, dtype=tc.dtype) + nan32\n",
    "    for i in range(MAX_VALID):\n",
    "        temp = tc * (mvalid >= i) / (repeatf // f) + mbase * (mvalid < i)\n",
    "        temp.sort()\n",
    "        tcfb[i] = temp.sum()\n",
    "        temp = ho * (mvalid >= i) + mbase * (mvalid < i)\n",
    "        temp.sort()\n",
    "        hofb[i] = temp.sum()\n",
    "    hoi, hobest = hofb.argmin(), hofb.min()\n",
    "    tci, tcbest = tcfb.argmin(), tcfb.min()\n",
    "    return (tcbest, hobest), (tci, hoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True) # no fall back\n",
    "def _alg_evaluate_canon(X0, Y0, W0, X1, Y1, W1, Xt, Yt, Wt, Xh, Yh, Wh, m, mvalid, mbase, k, subk, f):\n",
    "    tc = np.empty(m, dtype=Yt.dtype) + nan32\n",
    "    ho = np.empty(m, dtype=Yh.dtype) + nan32\n",
    "    #model = np.empty((m, subk.shape[0]), dtype=Xt.dtype) + nan32\n",
    "    repeatf = X0.shape[0]\n",
    "    for g in range(m):\n",
    "        X0g, Y0g, W0g, X1g, Y1g, W1g, xt, yt, wt, xh, yh, wh = (\n",
    "            X0[:, :, g::m][:, :, subk], Y0[:, :, g], W0[:, :, g],\n",
    "            X1[:, :, g::m][:, :, subk], Y1[:, :, g], W1[:, :, g],\n",
    "            Xt[:, g::m][:, subk], Yt[:, g], Wt[:, g],\n",
    "            Xh[:, g::m][:, subk], Yh[:, g], Wh[:, g])\n",
    "        tcg = np.empty(repeatf, dtype=Y0g.dtype) + nan32\n",
    "        for i in range(repeatf):\n",
    "            x0, y0, w0, x1, y1, w1 = X0g[i], Y0g[i], W0g[i], X1g[i], Y1g[i], W1g[i]\n",
    "            beta = _lr_fit(x0, y0, w0)\n",
    "            y1_ = _lr_predict(x1, beta)\n",
    "            tcg[i] = _lr_rss(y1, y1_, w1)\n",
    "        tcg.sort()\n",
    "        tc[g] = tcg.sum()\n",
    "        beta = _lr_fit(xt, yt, wt)\n",
    "        #model[g] = beta\n",
    "        yh_ = _lr_predict(xh, beta)\n",
    "        ho[g] = _lr_rss(yh, yh_, wh)\n",
    "    tc.sort()\n",
    "    ho.sort()\n",
    "    return (tc.sum() / (repeatf // f), ho.sum()), 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def _alg_finalize_expfb(Xt, Yt, Wt, Xh, m, mvalid, k, subk, val, exp):\n",
    "    model = np.empty((m, subk.shape[0]), dtype=Xt.dtype) + nan32\n",
    "    Yh_ = np.empty((Xh.shape[0], m), dtype=Xt.dtype) + nan32\n",
    "    for g in range(m): # loop for each stock\n",
    "        xt, yt, wt, xh = (\n",
    "            Xt[:, g::m][:, subk], Yt[:, g], Wt[:, g],\n",
    "            Xh[:, g::m][:, subk])\n",
    "        beta = _lr_fit(xt, yt, wt)\n",
    "        model[g] = beta\n",
    "        yh_ = _lr_predict(xh, beta)\n",
    "        if val >= mvalid[g] - subk.shape[0]:\n",
    "            Yh_[:, g] = 0\n",
    "        else:\n",
    "            if exp == 0:\n",
    "                Yh_[:, g] = yh_\n",
    "            else:\n",
    "                Yh_[:, g] = _exp_weigh(yh_, (mvalid[g] - subk.shape[0] - val) / exp)\n",
    "    return model, Yh_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True) # no fall back\n",
    "def _alg_finalize_canon(Xt, Yt, Wt, Xh, m, mvalid, k, subk):\n",
    "    model = np.empty((m, subk.shape[0]), dtype=Xt.dtype) + nan32\n",
    "    Yh_ = np.empty((Xh.shape[0], m), dtype=Xt.dtype) + nan32\n",
    "    for g in range(m):\n",
    "        xt, yt, wt, xh = (\n",
    "            Xt[:, g::m][:, subk], Yt[:, g], Wt[:, g],\n",
    "            Xh[:, g::m][:, subk])\n",
    "        beta = _lr_fit(xt, yt, wt)\n",
    "        model[g] = beta\n",
    "        Yh_[:, g] = _lr_predict(xh, beta)\n",
    "    return model, Yh_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def _alg_alltrain_expfb(X0, Y0, W0, X1, Y1, W1, Xt, Yt, Wt, Xh, Yh, Wh, m, mvalid, mbase, k, subk, f, _val, _exp):\n",
    "    Mval, Mexp = len(_val), len(_exp)\n",
    "    tc = np.zeros((m, Mval, Mexp), dtype=Yt.dtype) # zeros because we need to add to this for each fold\n",
    "    #model = np.empty((m, subk.shape[0]), dtype=Xt.dtype) + nan32\n",
    "    repeatf = X0.shape[0]\n",
    "    for g in range(m): # loop for each stock\n",
    "        X0g, Y0g, W0g, X1g, Y1g, W1g = (\n",
    "            X0[:, :, g::m][:, :, subk], Y0[:, :, g], W0[:, :, g],\n",
    "            X1[:, :, g::m][:, :, subk], Y1[:, :, g], W1[:, :, g])\n",
    "        ############## TRCV dataset\n",
    "        for p in range(repeatf): # loop for each cv-fold\n",
    "            x0, y0, w0, x1, y1, w1 = X0g[p], Y0g[p], W0g[p], X1g[p], Y1g[p], W1g[p]\n",
    "            beta = _lr_fit(x0, y0, w0)\n",
    "            y1_ = _lr_predict(x1, beta)\n",
    "            # search over the exp fallback\n",
    "            thei = Mval\n",
    "            for i in range(Mval): # i + 1 = min num of obs in stock - ddof to use lin model\n",
    "                if _val[i] >= mvalid[g] - subk.shape[0]:\n",
    "                    thei = i\n",
    "                    break\n",
    "                tc[g, i, 0] += _lr_rss(y1, y1_, w1) # when j == 0 just use the linear model\n",
    "                for j in range(1, Mexp): # j denotes exponential weighting argument\n",
    "                    y1_fb = _exp_weigh(y1_, (mvalid[g] - subk.shape[0] - _val[i]) / _exp[j])\n",
    "                    tc[g, i, j] += _lr_rss(y1, y1_fb, w1)\n",
    "        # outside the cv-fold loop\n",
    "        tc[g] /= repeatf // f # divide by number of times trcv set was repeated over\n",
    "        tc[g, thei:] = mbase[g] # fill in the mean model prediction errors for when mvalid[g] < i\n",
    "        #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%\n",
    "    tcfb = tc.sum(axis=0)\n",
    "    tcij, tcbest = tcfb.argmin(), tcfb.min()\n",
    "    return (tcbest, 0), (_val[tcij // Mexp], _exp[tcij % Mexp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True) # no fall back\n",
    "def _alg_alltrain_canon(X0, Y0, W0, X1, Y1, W1, Xt, Yt, Wt, Xh, Yh, Wh, m, mvalid, mbase, k, subk, f):\n",
    "    tc = np.empty(m, dtype=Yt.dtype) + nan32\n",
    "    #model = np.empty((m, subk.shape[0]), dtype=Xt.dtype) + nan32\n",
    "    repeatf = X0.shape[0]\n",
    "    for g in range(m):\n",
    "        X0g, Y0g, W0g, X1g, Y1g, W1g = (\n",
    "            X0[:, :, g::m][:, :, subk], Y0[:, :, g], W0[:, :, g],\n",
    "            X1[:, :, g::m][:, :, subk], Y1[:, :, g], W1[:, :, g])\n",
    "        tcg = np.empty(repeatf, dtype=Y0g.dtype) + nan32\n",
    "        for i in range(repeatf):\n",
    "            x0, y0, w0, x1, y1, w1 = X0g[i], Y0g[i], W0g[i], X1g[i], Y1g[i], W1g[i]\n",
    "            beta = _lr_fit(x0, y0, w0)\n",
    "            y1_ = _lr_predict(x1, beta)\n",
    "            tcg[i] = _lr_rss(y1, y1_, w1)\n",
    "        tcg.sort()\n",
    "        tc[g] = tcg.sum()\n",
    "    tc.sort()\n",
    "    return (tc.sum() / (repeatf // f), 0), ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True) #deprecated\n",
    "def _alg_evaluate_2(X0, Y0, W0, X1, Y1, W1, Xt, Yt, Wt, Xh, Yh, Wh, m, k, subk):\n",
    "    tc = np.empty(m, dtype=Yt.dtype) + nan32\n",
    "    ho = np.empty(m, dtype=Yh.dtype) + nan32\n",
    "    #model = np.empty((m, subk.shape[0]), dtype=Xt.dtype) + nan32\n",
    "    repeat = X0.shape[0]\n",
    "    for g in range(m):\n",
    "        X0g, Y0g, W0g, X1g, Y1g, W1g, xt, yt, wt, xh, yh, wh = (\n",
    "            X0[:, :, g::m][:, :, subk], Y0[:, :, g], W0[:, :, g],\n",
    "            X1[:, :, g::m][:, :, subk], Y1[:, :, g], W1[:, :, g],\n",
    "            Xt[:, g::m][:, subk], Yt[:, g], Wt[:, g],\n",
    "            Xh[:, g::m][:, subk], Yh[:, g], Wh[:, g])\n",
    "        tcg = np.empty(repeat * 2, dtype=Y0g.dtype) + nan32\n",
    "        for i in range(repeat):\n",
    "            x0, y0, w0, x1, y1, w1 = X0g[i], Y0g[i], W0g[i], X1g[i], Y1g[i], W1g[i]\n",
    "            beta0, beta1 = _lr_fit(x0, y0, w0), _lr_fit(x1, y1, w1)\n",
    "            y1_, y0_ = _lr_predict(x1, beta0), _lr_predict(x0, beta1)\n",
    "            tcg[2 * i], tcg[2 * i + 1] = _lr_rss(y1, y1_, w1), _lr_rss(y0, y0_, w0)\n",
    "        tcg.sort()\n",
    "        tc[g] = tcg.sum()\n",
    "        beta = _lr_fit(xt, yt, wt)\n",
    "        #model[g] = beta\n",
    "        yh_ = _lr_predict(xh, beta)\n",
    "        ho[g] = _lr_rss(yh, yh_, wh)\n",
    "    tc.sort()\n",
    "    ho.sort()\n",
    "    return (tc.sum() / 2, ho.sum())#, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def _lr_add_intercept(x): # NOT USED\n",
    "    return np.concatenate((np.ones((x.shape[0], 1)), x), axis=1)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _lr_fit(x, y, w):\n",
    "    wsqrt = w ** 0.5\n",
    "    thing = np.linalg.lstsq(np.expand_dims(wsqrt, 1) * x, wsqrt * y)\n",
    "    return thing[0]\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _lr_predict(x, beta):\n",
    "    return x @ beta.astype(x.dtype)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _lr_rss(y, y_, w):\n",
    "    res = (y_ - y) ** 2 * w\n",
    "    res.sort()\n",
    "    return res.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 0\n",
      "[] ()\n",
      "\n",
      "<13> 0\n",
      "1.0288687417628994 0.9984496220555278 1\n",
      "[x4] (8,)\n",
      "\n",
      "<12> 0\n",
      "1.6107278811722803 1.0470519319703233 2\n",
      "[x4, x5] (8, 9)\n",
      "\n",
      "<11> 0\n",
      "4.280990805481705 1.4171353539242328 3\n",
      "[x2, x4, x5] (2, 8, 9)\n",
      "\n",
      "<10> 0\n",
      "4.841844442439121 2.036917539934384 4\n",
      "[x2, x4, x5, x6] (2, 8, 9, 10)\n",
      "\n",
      "<9> 0\n",
      "5.318702137596149 5.774650711803322 5\n",
      "[x0, x2, x4, x5, x6] (0, 2, 8, 9, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    o = O()\n",
    "    def_W(o)\n",
    "    def_Y(o)\n",
    "    def_X(o)\n",
    "    from models.split import split\n",
    "    s = split2(o.X)\n",
    "    ta = TheAlg(o.Xa, o.Ya, o.Wa, s)\n",
    "    ta._setup()\n",
    "    ta.alg1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
