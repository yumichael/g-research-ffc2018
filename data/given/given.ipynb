{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/pandas/core/common.py:701: RuntimeWarning: divide by zero encountered in log\n",
      "  return func(obj, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "N_TRAIN, N_TEST = 623817, 640430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate hdf5 from original files\n",
    "if __name__ == '__main__':\n",
    "    from decimal import Decimal\n",
    "    df = pd.read_csv('train.csv', index_col=0, dtype={'y': str})\n",
    "    df.index = df.index - N_TRAIN\n",
    "    df.y = (df.y.map(Decimal) * 10000).astype(float)\n",
    "    df.columns.values[-1] = 'w'\n",
    "    df.to_hdf(top_dir + '/data/given/train.hdf5', mode='w', key='df')\n",
    "    dg = pd.read_csv('test.csv', index_col=0)\n",
    "    dg.to_hdf(top_dir + '/data/given/test.hdf5', mode='w', key='dg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_hdf(top_dir + 'data/given/train.hdf5')\n",
    "    dg = pd.read_hdf(top_dir + 'data/given/test.hdf5')\n",
    "except FileNotFoundError:\n",
    "    if __name__ != '__main__':\n",
    "        raise\n",
    "    df = pd.read_csv(top_dir + 'data/given/train.csv', index_col=0)\n",
    "    df.index = df.index - N_TRAIN\n",
    "    df.y *= 10000\n",
    "    dg = pd.read_csv(top_dir + 'data/given/test.csv', index_col=0)\n",
    "dh = pd.concat([df, dg])\n",
    "dh.columns.name = 'Feature'\n",
    "dh['x3a'] = dh['x3A x3B x3C x3D x3E'.split()].mean(axis=1)\n",
    "dh['x3g'] = dh['x3A x3B x3C x3D x3E'.split()].pipe(np.log).mean(axis=1).pipe(np.exp)\n",
    "dh['wy'] = dh.w * dh.y\n",
    "dh['Index'] = dh.index\n",
    "dh['Count'] = 1\n",
    "df, dg = dh.loc[:-1], dh.loc[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_stock_wide(long):\n",
    "    orig_index, orig_type = long.index, type(long)\n",
    "    ref = dh.loc[long.index]\n",
    "    try:\n",
    "        long.index = pd.MultiIndex.from_arrays([ref.Day, ref.Stock])\n",
    "        wide = long.unstack() # unstacked level is autosorted\n",
    "        # # changed my mind, no swapping levels for columns to save time/space\n",
    "        #if issubclass(orig_type, pd.DataFrame):\n",
    "        #    wide = wide.swaplevel(axis=1)\n",
    "    finally:\n",
    "        long.index = orig_index\n",
    "    return wide\n",
    "makesw = make_stock_wide\n",
    "pd.DataFrame.makesw = makesw\n",
    "pd.Series.makesw = makesw\n",
    "\n",
    "def make_index_long_like(wide, ref=dh):\n",
    "    if isinstance(wide, pd.Series) and isinstance(wide.index, pd.MultiIndex):\n",
    "        raise ValueError('TODO support hierarchical wide index')\n",
    "    if isinstance(wide, pd.Series):\n",
    "        return ref.Stock.map(wide).rename(wide.name)\n",
    "    if isinstance(wide, pd.DataFrame):\n",
    "        long = wide.T.unstack().T\n",
    "        idcs = ref.Index.makesw().T.unstack().T.rename('Index')\n",
    "        #assert (stacked.index == idcs.index).all()\n",
    "        long.index = idcs\n",
    "        long = long[~long.index.isna()]\n",
    "        long.index = long.index.astype(np.int64)\n",
    "        long.sort_index(inplace=True)\n",
    "        #assert (long.index == ref.index).all()\n",
    "        return long\n",
    "makeil_like = make_index_long_like\n",
    "pd.DataFrame.makeil_like = makeil_like\n",
    "pd.Series.makeil_like = makeil_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_n_valid_days_filter(dh, n_valid=None):\n",
    "    if n_valid is None:\n",
    "        dh, n_valid = globals()['dh'], dh\n",
    "    return dh.groupby('Stock').y.transform(lambda x: x.count() >= n_valid).rename('Valid')\n",
    "index_nvdf = index_n_valid_days_filter\n",
    "\n",
    "def stock_n_valid_days_filter(dh, n_valid):\n",
    "    if n_valid is None:\n",
    "        dh, n_valid = globals()['dh'], dh\n",
    "    return dh.groupby('Stock').y.agg(lambda x: x.count() >= n_valid).rename('Valid')\n",
    "stock_nvdf = stock_n_valid_days_filter\n",
    "\n",
    "def day_filter(df, n_valid, stock='Stock'):\n",
    "    '''Params - df: `DataFrame` with a 'Stock' and 'y' column,\n",
    "                n_valid: minimum number of valid entries to keep a stock,\n",
    "                stock: just 'Stock', or the `Series` containing the groupby value\n",
    "    Filters `df` for only stock entries that mean minimum `n_valid` observations in the `y` variable'''\n",
    "    return df.groupby('Stock').filter(lambda x: x.y.count() >= n_valid)\n",
    "\n",
    "dff = day_filter(df, 246)\n",
    "dhh = day_filter(dh, 1)\n",
    "dhf = day_filter(dh, 246)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-623817\n",
      "{1917}\n",
      "{43289}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(dh.index[0])\n",
    "    print(set(df.Stock.unique()) ^ set(range(3023)))\n",
    "    print(set(dh.index) - set(dhh.index))\n",
    "dfh = dh.loc[list(range(dh.index[0], 0)) + [43289]]\n",
    "dfh.index = list(dfh.index[:-1]) + [-623818]\n",
    "dfh.sort_index(inplace=True)\n",
    "dfh.iloc[0, 0] = -1\n",
    "dfh.iloc[0, 1] = 1\n",
    "dfh.iloc[0, 2] = 1917\n",
    "for j in range(4, 15):\n",
    "    dfh.iloc[0, j] = np.nan\n",
    "dfh.iloc[0, 17] = -623818\n",
    "dfh.iloc[0, 18] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_TRAIN, N_TEST = len(df), len(dg) # should be 623817, 640430\n",
    "N_STOCK = dh.Stock.nunique() # should be 3023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xfeats = 'x0 x1 x2 x3A x3B x3C x3D x3E x4 x5 x6'.split()\n",
    "xofeats = 'x0 x1 x2 x3A x3B x3C x3D x3E x4 x5 x6 x3a x3g'.split()\n",
    "x_feats = 'x0 x1 x2 x3a x4 x5 x6'.split()\n",
    "xxfeats = 'x0 x1 x2 x3a x4 x5 x3g'.split()\n",
    "xafeats = 'x0 x1 x2 x3a x4 x5'.split()\n",
    "xgfeats = 'x0 x1 x2 x3g x4 x5'.split()\n",
    "x3feats = 'x3A x3B x3C x3D x3E'.split()\n",
    "idfeats = 'Market Stock'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stockmarket = dh.groupby('Stock').Market.first()\n",
    "stockimportance = (dh.y ** 2 * dh.w).groupby(dh.Stock).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def def_W(namespace, dh=dh, include=''):\n",
    "    '''Params - namespace: e.g. `globals()`, dh: `dh` or sub-DataFrame of it (`dh` itself is recommended)\n",
    "    Put convenience matrix variables into `namespace`'''\n",
    "    include_list = include.split()\n",
    "    o = O()\n",
    "    o.W = dh.w.pipe(makesw)\n",
    "    o.Wa = o.W.fillna(0)\n",
    "    if 'nrm' in include_list:\n",
    "        o.Wnrm = o.W.pipe(lambda w: w / w.sum())\n",
    "        o.Wnrma = o.Wnrm.fillna(0)\n",
    "    o._standardize = lambda X: (X - X.wmean(o.W)) / np.sqrt(X.wvar(o.W))\n",
    "    o._dewmean = lambda X: X - X.wmean(o.W)\n",
    "    o._scale = lambda X: X / np.sqrt(X.wvar(o.W))\n",
    "    dict.update(namespace, **o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def def_Y(namespace, dh=dh, include=''):\n",
    "    include_list = include.split()\n",
    "    o = O(W=namespace['W'])\n",
    "    o.Y = dh.y.pipe(makesw)\n",
    "    o.Ya = o.Y.fillna(0)\n",
    "    o.Y_wmean = o.Y.wmean(o.W).rename('y$wmean')\n",
    "    o.Y_wvar = o.Y.wvar(o.W).rename('y$wvar')\n",
    "    o.Y_wvar = (o.Y_wvar.fillna((o.Y ** 2).sum().chain.fillna(1, inplace=True))).rename('y$wvar.a')\n",
    "    o.Y_wzvar = ((o.Y ** 2 * o.W).sum() / o.W.sum()).chain.fillna(1, inplace=True).rename('y$zvar.a')\n",
    "    if 'scl' in include_list:\n",
    "        o.Yscl = o.Y / np.sqrt(o.Y_wzvar)\n",
    "        o.Wscl = o.W * o.Y_wzvar\n",
    "    if 'std' in include_list:\n",
    "        o.Ystd = (o.Y - o.Y_wmean) / np.sqrt(o.Y_wvar)\n",
    "        o.Ystda = o.Ystd.fillna(0)\n",
    "        o.Wstd = o.W * o.Y_wvar\n",
    "    dict.update(namespace, **o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def def_X(namespace, dh=dh, include='', feats=None):\n",
    "    include_list = include.split()\n",
    "    feats = feats.split() if isinstance(feats, str) else feats\n",
    "    dhfeats = dh[[c for c in dh.columns if c[0] == 'x']] if feats is None else dh[feats]\n",
    "    o = O(W=namespace['W'], Wa=namespace['Wa'])\n",
    "    o.X = dhfeats.pipe(makesw)\n",
    "    o.Xa = o.X.fillna(0)\n",
    "    if 'log' in include_list or 'logs' in include_list:\n",
    "        o.Xlog = o.X.pipe(np.log).colname_append('.log', level=0)\n",
    "        o.Xlogz0 = o.Xlog.replace(-np.inf, np.nan)\n",
    "        o.Xiszero = (o.Xlog == -np.inf).astype(np.int8)\n",
    "        o.Xlogz1 = (o.Xiszero * (o.Xlogz0.min() - 1) + o.Xlog.replace(-np.inf, 0)).colname_append('.z(1)', level=0)\n",
    "        o.Xlogz3 = (o.Xiszero * -93 + o.Xlog.replace(-np.inf, 0)).colname_append('.zc(-93)', level=0)\n",
    "        o.Xlogz4 = (o.Xiszero * -194 + o.Xlog.replace(-np.inf, 0)).colname_append('.zc(-93)', level=0)\n",
    "        if 'logs' in include_list:\n",
    "            if 'z1' in include_list:\n",
    "                o.Xlogz1_wmed = o.Xlogz1.wmedian(o.W.repeat_like(o.Xlogz1))\n",
    "                o.Xlogz1_wmean = o.Xlogz1.wmean(o.W.repeat_like(o.Xlogz1))\n",
    "                if 355 in o.Xlogz1.index:\n",
    "                    o.Xlogz1_wmed[o.Xlogz1_wmed.isna()] = o.Xlogz1.loc[355, (ss, 1917)]\n",
    "                    o.Xlogz1_wmean[o.Xlogz1_wmean.isna()] = o.Xlogz1.loc[355, (ss, 1917)]\n",
    "                _temp = o.Xlogz1.wvar(o.W.repeat_like(o.Xlogz1)) + 1\n",
    "                o.Xlogz1_wvar = _temp.chain.replace(np.inf, 5, inplace=True).chain.fillna(5, inplace=True) #\"TODO\"\n",
    "                o.Xlogz1s = (o.Xlogz1 - o.Xlogz1_wmean / np.sqrt(o.Xlogz1_wvar)).colname_append('.std', level=0)\n",
    "                o.Xlogz1sa = o.Xlogz1s.fillna(0).colname_append('.a', level=0)\n",
    "                o.Xlogz1ms = (o.Xlogz1 - o.Xlogz1_wmed / np.sqrt(o.Xlogz1_wvar)).colname_append('.mstd', level=0)\n",
    "                o.Xlogz1msa = o.Xlogz1ms.fillna(0).colname_append('.a', level=0)\n",
    "            if 'z3' in include_list:\n",
    "                o.Xlogz3_wmed = o.Xlogz3.wmedian(o.W.repeat_like(o.Xlogz3))\n",
    "                o.Xlogz3_wmean = o.Xlogz3.wmean(o.W.repeat_like(o.Xlogz3))\n",
    "                if 355 in o.Xlogz3.index:\n",
    "                    o.Xlogz3_wmed[o.Xlogz3_wmed.isna()] = o.Xlogz3.loc[355, (ss, 1917)]\n",
    "                    o.Xlogz3_wmean[o.Xlogz3_wmean.isna()] = o.Xlogz3.loc[355, (ss, 1917)]\n",
    "                _temp = o.Xlogz3.wvar(o.W.repeat_like(o.Xlogz3)) + 1\n",
    "                o.Xlogz3_wvar = _temp.chain.replace(np.inf, 5, inplace=True).chain.fillna(5, inplace=True) #\"TODO\"\n",
    "                o.Xlogz3s = (o.Xlogz3 - o.Xlogz3_wmean / np.sqrt(o.Xlogz3_wvar)).colname_append('.std', level=0)\n",
    "                o.Xlogz3sa = o.Xlogz3s.fillna(0).colname_append('.a', level=0)\n",
    "                o.Xlogz3ms = (o.Xlogz3 - o.Xlogz3_wmed / np.sqrt(o.Xlogz3_wvar)).colname_append('.mstd', level=0)\n",
    "                o.Xlogz3msa = o.Xlogz3ms.fillna(0).colname_append('.a', level=0)\n",
    "            if 'z4' in include_list:\n",
    "                o.Xlogz4_wmed = o.Xlogz4.wmedian(o.W.repeat_like(o.Xlogz4))\n",
    "                o.Xlogz4_wmean = o.Xlogz4.wmean(o.W.repeat_like(o.Xlogz4))\n",
    "                if 355 in o.Xlogz4.index:\n",
    "                    o.Xlogz4_wmed[o.Xlogz4_wmed.isna()] = o.Xlogz4.loc[355, (ss, 1917)]\n",
    "                    o.Xlogz4_wmean[o.Xlogz4_wmean.isna()] = o.Xlogz4.loc[355, (ss, 1917)]\n",
    "                _temp = o.Xlogz4.wvar(o.W.repeat_like(o.Xlogz4)) + 1\n",
    "                o.Xlogz4_wvar = _temp.chain.replace(np.inf, 5, inplace=True).chain.fillna(5, inplace=True) #\"TODO\"\n",
    "                o.Xlogz4s = (o.Xlogz4 - o.Xlogz4_wmean / np.sqrt(o.Xlogz4_wvar)).colname_append('.std', level=0)\n",
    "                o.Xlogz4sa = o.Xlogz4s.fillna(0).colname_append('.a', level=0)\n",
    "                o.Xlogz4ms = (o.Xlogz4 - o.Xlogz4_wmed / np.sqrt(o.Xlogz4_wvar)).colname_append('.mstd', level=0)\n",
    "                o.Xlogz4msa = o.Xlogz4ms.fillna(0).colname_append('.a', level=0)\n",
    "    if 'wqtl' in include_list or 'wnrm' in include_list:\n",
    "        o.Xwqtl = o.X.wqtl(o.Wa)\n",
    "        if 'wnrm' in include_list:\n",
    "            from scipy.stats import norm\n",
    "            o.Xwnrm = (o.Xwqtl.pipe(norm.ppf) + o.Xwqtl * 0).colname_append('.wnrm', level=0)\n",
    "            o.Xwnrma = o.Xwnrm.fillna(0).colname_append('.a', level=0)\n",
    "        o.Xwqtl = o.Xwqtl.colname_append('.wqtl', level=0)\n",
    "        o.Xwqtla = o.Xwqtl.fillna(0.5).colname_append('.a', level=0)\n",
    "    dict.update(namespace, **o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def def_misc(namespace, dh=dh):\n",
    "    o = O(Y=namespace['Y'], W=namespace['W'])\n",
    "    o.stock_wmean = Y.wmean(W)\n",
    "    o.index_importance = dh.w * dh.y ** 2\n",
    "    o.stock_importance = (W * Y ** 2).sum()\n",
    "    o.stock_importance__wmean = (W * (Y - Y.wmean(W)) ** 2).sum()\n",
    "    dict.update(namespace, **o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
